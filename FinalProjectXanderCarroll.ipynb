{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Darwin Plays Super Mario Bros\n",
    "### *Training A Reward-Based Machine Learning Model to Play Classic Video Games*\n",
    "\n",
    "\n",
    "**Author:** Xander Carroll    \n",
    "**Course:** Physics 5680, Autumn 2025  \n",
    "**Date:** October 30, 2025\n",
    "\n",
    "**Project Repository:** [Link](https://github.com/Xander-Carroll/PHYSICS5680-Neural-Network-Final)\n",
    "&nbsp;\n",
    "\n",
    "<small>*I used GPT-5 mini to help craft several paragraphs of text throughout this notebook.*</small>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Classic video games offer a controlled and well-understood environment for experimenting with machine learning, providing clear objectives and measurable rewards without the complexity of modern games. This project will explore training a reward-based neural network to play Super Mario Bros on the Nintendo Entertainment System (NES). The game state will be extracted using an NES emulator and encoded into a representation suitable for a neural network. The network will then be trained to maximize in-game rewards such as level progress and the level timer. It is anticipated that this approach will demonstrate how simple, reward-driven models can learn effective strategies in constrained environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### Problem Description\n",
    "Developing artificial agents that can learn to play video games has long been a benchmark problem in machine learning and artificial intelligence. While modern games offer highly complex environments, classic games like Super Mario Bros for the Nintendo Entertainment System (NES) provide simpler, well-defined environments where objectives, rewards, and state representations are clear. The problem we aim to solve is training a reward-based neural network to play Super Mario Bros, using in-game feedback to guide learning. This requires designing a system that can interpret the game state, map it into a format suitable for a neural network, and optimize agent behavior to choose the controller inputs that will maximize cumulative rewards.\n",
    "\n",
    "### Motivation\n",
    "This project advances research in reinforcement learning by testing how reward-based neural networks can learn behavior in simple, well-defined environments. Classic games like Super Mario Bros provide an ideal platform for such experiments. It is easy to simulate, has clear objectives, and still requires sequential decision-making and adaptation. By evolving a neural network to play the game using only in-game rewards as feedback, this project explores how complex behavior can emerge from simple fitness functions.\n",
    "\n",
    "### Background\n",
    "Our primary environment is the NES version of [Super Mario Bros](https://en.wikipedia.org/wiki/Super_Mario_Bros).$`^1`$ This game is one of the most popular from its era, has been reverse engineered, and is very well documented by the community. Super Mario Bros is a side-scrolling platformer. The player's goal is to make forward progress, eventually reaching the end of the level while avoiding hazards. The [BizHawk](https://tasvideos.org/Bizhawk) NES emulator will be used to provide a programmatic interface to read the game's memory and feed controller inputs to the game in real-time.$`^2`$ This will allow the neural network to \"see\" and \"interact\" with the game. The problem is framed as a reward-based learning task, where the agent receives feedback proportional to in-game progress, creating a natural fitness function for optimization.\n",
    "\n",
    "### Inputs and Outputs\n",
    "Input(s): The algorithm will recieve the current game state from the BizHawk emulator. This will include a map of the level, with terrain layout, enemy locations, and the player's current progress. This information will be encoded into a representation suitable for neural network processing.\n",
    "\n",
    "Output(s): The network will produce a set of controller inputs (e.g., hold left, press button A) to be executed in the game environment. Eventually, we expect these controller outputs to maximize the fitness function (player's foward progress in the level). \n",
    "\n",
    "### Project Goals\n",
    "\n",
    "1. **Primary Goal:**\n",
    "Train a fitness-based neural network to autonomously play Super Mario Bros and achieve measurable progress through one or more levels. The primary metric is maximizing cumulative in-game reward, including level completion.\n",
    "\n",
    "1. **Stretch Goal:**\n",
    "Extend the model to generalize across multiple levels or similar games. This will include testing whether a network trained on one level can adapt to unseen layouts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related Work\n",
    "\n",
    "*(This section should briefly review key studies or projects relevant to your topic.)*\n",
    "\n",
    "Make sure you address the following in this section:\n",
    "\n",
    "* **Methodological Review:** Find and group existing papers or projects based on their methodological approaches.\n",
    "* **Strengths and Weaknesses:** Discuss the pros and cons of these approaches and how they compare to your work.\n",
    "* **State-of-the-Art:** Highlight clever or effective methods you found and describe the current state-of-the-art in the field.\n",
    "* **References:** Include at least 3-5 relevant references, covering previous attempts and methods applied to similar problems. *Note: Google Scholar is great for sourcing papers and managing citations: https://scholar.google.com/.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ethical Considerations\n",
    "\n",
    "*(This section should be 1-2 paragraphs.)*\n",
    "\n",
    "Machine learning models can have a significant societal impact. Briefly discuss the ethical implications of your project.\n",
    "\n",
    "* **Data Privacy & Bias:** Where did your data come from? Does it contain sensitive information? Could the dataset or the way it was collected introduce bias (e.g., gender, racial, or geographical bias)?\n",
    "* **Potential Misuse:** Could the algorithm or its results be used for malicious or harmful purposes?\n",
    "* **Impact:** Who could be positively or negatively affected by the application of your model in the real world?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "\n",
    "## 4. Project Setup and Imports\n",
    "\n",
    "*(This initial section is for setting up your project's environment. It includes importing the necessary Python libraries and documenting their versions to ensure your work is reproducible.)*\n",
    "\n",
    "### 1.1. Key Libraries\n",
    "\n",
    "Below is a brief description of the primary Python packages that will be used in this project.\n",
    "\n",
    "  * **pandas:** Used for data manipulation and analysis. It provides powerful data structures, like the DataFrame, for handling and exploring structured data.\n",
    "  * **numpy:** The fundamental package for scientific computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "  * **matplotlib & seaborn:** These are libraries for data visualization. Matplotlib is a comprehensive library for creating static visualizations, while Seaborn provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "  * **Plotly:** A graphing library used to create interactive, publication-quality visualizations.  This is especially useful for creating dynamic plots that allow for zooming, panning, and hovering to inspect data points.\n",
    "  * **scikit-learn:** A primary machine learning library that provides simple and efficient tools for data mining and data analysis, including a wide range of classification, regression, and clustering algorithms.\n",
    "  * **TensorFlow:** An end-to-end open-source platform for machine learning, specializing in deep learning. It is used for building and training neural networks for tasks like image classification, natural language processing, and more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST AN EXAMPLE!!! Yours will probably be different!!\n",
    "\n",
    "# Import all necessary libraries here\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import plotly\n",
    "# import plotly.express as px\n",
    "# import sklearn\n",
    "# import tensorflow as tf\n",
    "# import sys\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "# # Configure plots for readability\n",
    "# plt.rcParams['figure.figsize'] = (10, 6)\n",
    "# plt.rcParams['font.size'] = 14\n",
    "\n",
    "# print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2. Version Information\n",
    "\n",
    "*(To ensure that the results in this notebook can be reproduced, it is important to record the versions of the key libraries used. The code below will print the versions of Python and the packages listed above.)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST AN EXAMPLE!!! Yours will probably be different!!\n",
    "# Print version information\n",
    "# print(f\"Python version: {sys.version}\")\n",
    "# print(f\"pandas version: {pd.__version__}\")\n",
    "# print(f\"numpy version: {np.__version__}\")\n",
    "# print(f\"seaborn version: {sns.__version__}\")\n",
    "# print(f\"plotly version: {plotly.__version__}\")\n",
    "# print(f\"scikit-learn version: {sklearn.__version__}\")\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Dataset\n",
    "\n",
    "*This should be quite extensive.*\n",
    "\n",
    "Describe the dataset(s) you are using for your project.\n",
    "\n",
    "* **Description:** What is your dataset? How many training, validation, and test examples are there?\n",
    "* **Preprocessing:** Discuss any preprocessing techniques you applied, such as normalization, handling missing values, or data augmentation.\n",
    "* **Data Specifics:** Provide details on data specifics, e.g., image resolution, time-series discretization, or text encoding.\n",
    "* **Source:** Cite the source from where you obtained your dataset.\n",
    "* **Visualization:** You **must** show examples of your data.\n",
    "    * Display examples from your dataset, especially examples from different classes.\n",
    "    * Highlight and display important features that describe your dataset and/or are nmeeded for classification/regression/clustering.\n",
    "\n",
    "\n",
    "**NOTE:** All figures need legends, axis labels, and readable font sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset here (e.g., from a CSV file)\n",
    "# df = pd.read_csv('path/to/your/data.csv')\n",
    "\n",
    "# Perform any necessary preprocessing steps\n",
    "# - Handle missing values\n",
    "# - Normalize numerical features\n",
    "# - Encode categorical variables\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# print(f\"Training set size: {len(train_df)}\")\n",
    "# print(f\"Validation set size: {len(val_df)}\")\n",
    "# print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations to understand your data\n",
    "# - Histograms of feature distributions\n",
    "# - Correlation heatmaps\n",
    "# - Example data points (e.g., show a few images or text samples)\n",
    "\n",
    "# Example: Plot a histogram of a feature named 'age'\n",
    "# sns.histplot(data=df, x='age', kde=True)\n",
    "# plt.title('Distribution of Age')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Methods\n",
    "(This section should be about a few paragraphs, describing the methods you are using.)\n",
    "\n",
    "Describe the machine learning algorithm(s) you are using to address your problem. Focus on providing a clear, conceptual understanding of how each method works.\n",
    "\n",
    "- **Algorithm Description:** Explain the core idea behind each algorithm you used. What is its main goal and how does it approach the problem? For example, for a decision tree, you would explain how it splits data based on features to make decisions.\n",
    "\n",
    "- **Visual Aids:** Feel free to include figures or diagrams that help explain your algorithm. These can be powerful tools to illustrate complex ideas. NOTE: Any figures not made by you MUST have a clear reference to the original source.\n",
    "\n",
    "   Example:\n",
    "\n",
    "<img src=\"figs/text_embeddings.png\" \n",
    "        alt=\"Picture\" \n",
    "        width=\"600\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "<div style=\"text-align: right;\">\n",
    "<small><cite>Figure from: https://www.searchenginejournal.com/wp-content/uploads/2019/12/use-5de7e39f7ccbd.png</cite></small>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "- **Mathematical Detail (Optional):** You do not need to include detailed mathematical equations unless they are critical to understanding your specific implementation or a unique aspect of the algorithm you are highlighting.\n",
    "\n",
    "  Example:\n",
    "  \n",
    "  **The Cauchy-Schwarz Inequality**\n",
    "$$\\left( \\sum_{k=1}^n a_k b_k \\right)^2 \\leq \\left( \\sum_{k=1}^n a_k^2 \\right) \\left( \\sum_{k=1}^n b_k^2 \\right)$$\n",
    "\n",
    "- **Clarity:** Provide a concise description (approximately one paragraph) of how each algorithm works. Assume the reader is a fellow student in your major who may not be familiar with machine learning algorithms, so emphasize clarity and comprehension.\n",
    "\n",
    "- **Subsections:** If you use multiple methods, break them out into subsections for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Method 1: (e.g., Logistic Regression)\n",
    "\n",
    "*(Some explanatory text and figures if necessary.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Method 2: (e.g., Support Vector Machine)\n",
    "\n",
    "*(Some explanatory text and figures if necessary.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architectures, loss functions, and any helper functions here.\n",
    "\n",
    "# Example: Define a simple model using scikit-learn\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "#\n",
    "# model = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results\n",
    "\n",
    "*(This section should focus on the objective presentation of your findings. Present the data, metrics, and outputs from your experiments without interpretation.)*\n",
    "\n",
    "* **Experimental Setup:** Briefly describe how you conducted your experiments.\n",
    "    * **Hyperparameters:** Specify the final (hyper)parameters chosen for your models (e.g., learning rate, number of trees, regularization strength) and briefly mention the process used to select them (e.g., grid search, manual tuning).\n",
    "    * **Cross-Validation:** Describe your use of cross-validation, including the number of folds if applicable.\n",
    "* **Evaluation Metrics:** Clearly identify and explain the primary metrics you are using to evaluate your models (e.g., accuracy, precision, AUC, mean squared error). Provide the equations for any metrics that are not common.\n",
    "* **Quantitative Results:** Present your main findings using tables and plots. This is the core of your results section.\n",
    "    * For classification tasks, this should include final performance metrics and visualizations like confusion matrices or ROC/AUPRC curves. \n",
    "    * For regression tasks, this should include metrics like Mean Absolute Error (MAE) or R-squared values.\n",
    "* **Qualitative Results:** Show specific examples of your model's outputs.\n",
    "    * Display a few examples where the model performed correctly.\n",
    "    * It is also crucial to show a few representative examples of where your algorithm failed.\n",
    "\n",
    "**NOTE:** All figures need legends, axis labels, and readable font sizes. All tables should be clearly labeled.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model(s) on the training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation set to tune hyperparameters\n",
    "# val_predictions = model.predict(X_val)\n",
    "\n",
    "# Final evaluation on the test set\n",
    "# test_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots and tables to present your findings\n",
    "\n",
    "# Example: Plot a confusion matrix\n",
    "# cm = confusion_matrix(y_test, test_predictions)\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# Example: Create a results table\n",
    "# results = {\n",
    "#     'Model': ['Logistic Regression', 'SVM'],\n",
    "#     'Accuracy': [0.85, 0.92],\n",
    "#     'Precision': [0.83, 0.91]\n",
    "# }\n",
    "# results_df = pd.DataFrame(results)\n",
    "# display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Discussion\n",
    "\n",
    "*(In this section, you will interpret the results you presented above. Explain what your findings mean, analyze why the models behaved as they did, and discuss the implications of your work.)*\n",
    "\n",
    "* **Interpretation of Results:** What do your results from the previous section actually mean? For instance, does a 95% accuracy on your test set mean the problem is solved? Why or why not?\n",
    "* **Error Analysis:** Look at the qualitative results where your algorithm failed. Is there a pattern? Does the model consistently struggle with a specific class or type of data? Propose hypotheses for why these failures might be occurring.\n",
    "* **Comparison of Methods:** If you used multiple algorithms, which performed best? Discuss potential reasons for the difference in performance. Did one model's assumptions better fit the data?\n",
    "* **Overfitting:** Discuss any evidence of overfitting you observed (e.g., a large gap between training and validation performance). What steps did you take to mitigate it, and how effective were they?\n",
    "* **Limitations:** What are the main limitations of your work? This could be related to the size of your dataset, the features you used, or the assumptions made by your models.\n",
    "\n",
    "**NOTE:** Add sections as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions & Future Work\n",
    "\n",
    "* **Summary:** Summarize your report and reiterate the key findings.\n",
    "* **Performance:** Which algorithms were the highest-performing? Why do you think some algorithms worked better than others?\n",
    "* **Future Work:** If you had more time, more team members, or more computational resources, what would you explore next? (e.g., try different model architectures, collect more data, explore different features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1) https://github.com/Xander-Carroll/PHYSICS5680-Neural-Network-Final\n",
    "2) https://en.wikipedia.org/wiki/Super_Mario_Bros\n",
    "3) https://tasvideos.org/Bizhawk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
